{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubspaceModel(nn.Module):\n",
    "    def __init__(self, dim: int, num_basis: int) -> None:\n",
    "        super().__init__()\n",
    "        self.U = nn.Parameter(torch.empty((num_basis, dim)))\n",
    "        nn.init.orthogonal_(self.U)\n",
    "        self.L = nn.Parameter(torch.FloatTensor([i for i in range(num_basis)])) #\n",
    "        self.mu = nn.Parameter(torch.zeros(num_basis))\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.U.mm(self.L * z) + self.mu #\n",
    "\n",
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self,\n",
    "        in_channels: int, \n",
    "        out_channels: int, \n",
    "        kernel_size: int = 3, \n",
    "        stride: int = 1, \n",
    "        padding: int = 1, \n",
    "        padding_mode: str = \"zeros\", \n",
    "        # groups: int = 1, \n",
    "        # # bias: bool = True, \n",
    "        transposed: bool = False, \n",
    "        # normalization: str = None, \n",
    "        activation: bool = True, \n",
    "        pre_activate: bool = False\n",
    "        ) -> None:\n",
    "        if transposed:\n",
    "            conv = partial(nn.ConvTranspose2d, output_padding=stride - 1)\n",
    "            padding_mode = \"zeros\"\n",
    "        else:\n",
    "            conv = nn.Conv2d\n",
    "        \n",
    "        layers = [conv(\n",
    "                    in_channels, \n",
    "                    out_channels,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=stride,\n",
    "                    padding=padding,\n",
    "                    padding_mode=padding_mode\n",
    "                    )]\n",
    "        if activation:\n",
    "            if pre_activate:\n",
    "                layers.insert(0, nn.LeakyReLU())\n",
    "            else:\n",
    "                layers.append(nn.LeakyReLU())\n",
    "        super().__init__(*layers)\n",
    "\n",
    "class EigenBlock(nn.Module):\n",
    "    def __init__(self, \n",
    "    width: int, \n",
    "    height: int, \n",
    "    in_channels: int, \n",
    "    out_channels: int, \n",
    "    num_basis: int) -> None:\n",
    "        super().__init__()\n",
    "        self.subspacelayer = SubspaceModel(dim=width * height * in_channels, num_basis=num_basis)\n",
    "        self.subspace_conv1 = ConvLayer(\n",
    "            in_channels,\n",
    "            in_channels,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            transposed=True,\n",
    "            activation=False\n",
    "        )\n",
    "        self.subspace_conv2 = ConvLayer(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            transposed=True,\n",
    "            activation=False\n",
    "        )\n",
    "        self.feature_conv1 = ConvLayer(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            transposed=True,\n",
    "            pre_activate=True\n",
    "        )\n",
    "        self.feature_conv2 = ConvLayer(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            transposed=True,\n",
    "            pre_activate=True\n",
    "        )\n",
    "    \n",
    "    def forward(self, z, h):\n",
    "        phi = self.subspacelayer(z).view(h.shape)\n",
    "        h = self.feature_conv1(self.subspace_conv1(phi) + h)\n",
    "        h = self.feature_conv2(self.subspace_conv2(phi) + h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,\n",
    "        ) -> None:\n",
    "        super().__init__()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('PINNs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5651587e625deb4fe86239a16248888bca0533ef8a7ebc9a31b892346d8b21d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
